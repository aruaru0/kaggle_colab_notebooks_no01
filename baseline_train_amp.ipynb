{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "baseline-train-amp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "14930TinYxIM5HiZUwvXfCH6o4LzeV5FF",
      "authorship_tag": "ABX9TyO6DyZAIzZzEkU5C5czExWX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aruaru0/colab_notebook/blob/main/baseline_train_amp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjMgrtRPY3U4",
        "outputId": "10d81977-7de6-4b96-bec9-a9c436bcdcfb"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Aug 14 00:22:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmKCSEMitPlB",
        "outputId": "5786d3f6-4844-4737-b3eb-6a91e2a99561"
      },
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "cd apex\n",
        "pip install -v --disable-pip-version-check --no-cache-dir ./\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uycQW7i9tyBp"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-huBYiS2HPZ"
      },
      "source": [
        "#import os\n",
        "#assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecwl_27k2LAg"
      },
      "source": [
        "#!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JNtpo_VY3D7",
        "outputId": "3be02272-ebd6-4690-9a04-a5d6008f7cbd"
      },
      "source": [
        "!tar xvf /content/drive/MyDrive/datas/data/Label.tar"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label/\n",
            "label/val_finetune.txt\n",
            "label/train_finetune.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ3RBCmdZKpw"
      },
      "source": [
        "#!tar xf /content/drive/MyDrive/datas/data/Test.tar\n",
        "!tar xf /content/drive/MyDrive/datas/data/Train.tar\n",
        "!tar xf /content/drive/MyDrive/datas/data/Val.tar"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbueC_UmgpuP"
      },
      "source": [
        "# restart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzaR_U4GubJp",
        "outputId": "539037b0-bd9c-404d-8637-55bd9966129a"
      },
      "source": [
        "!sh setup.sh"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 8102, done.\u001b[K\n",
            "remote: Counting objects: 100% (189/189), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 8102 (delta 92), reused 124 (delta 63), pack-reused 7913\u001b[K\n",
            "Receiving objects: 100% (8102/8102), 14.16 MiB | 25.21 MiB/s, done.\n",
            "Resolving deltas: 100% (5491/5491), done.\n",
            "Using pip 21.1.3 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n",
            "Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/include/python3.7/UNKNOWN\n",
            "sysconfig: /usr/include/python3.7m/UNKNOWN\n",
            "Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/bin\n",
            "sysconfig: /usr/bin\n",
            "Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local\n",
            "sysconfig: /usr\n",
            "Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\n",
            "Non-user install because site-packages writeable\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-2i6tjmoi\n",
            "Created temporary directory: /tmp/pip-req-tracker-c822ejx7\n",
            "Initialized build tracking at /tmp/pip-req-tracker-c822ejx7\n",
            "Created build tracker: /tmp/pip-req-tracker-c822ejx7\n",
            "Entered build tracker: /tmp/pip-req-tracker-c822ejx7\n",
            "Created temporary directory: /tmp/pip-install-1pr2rrmy\n",
            "Processing /content/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-fv8v9gvh\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-c822ejx7'\n",
            "    Running setup.py (path:/tmp/pip-req-build-fv8v9gvh/setup.py) egg_info for package from file:///content/apex\n",
            "    Created temporary directory: /tmp/pip-pip-egg-info-ffcc8jrx\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.9.0+cu102\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-pip-egg-info-ffcc8jrx/apex.egg-info\n",
            "    writing /tmp/pip-pip-egg-info-ffcc8jrx/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-pip-egg-info-ffcc8jrx/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-pip-egg-info-ffcc8jrx/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-ffcc8jrx/apex.egg-info/SOURCES.txt'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-ffcc8jrx/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-fv8v9gvh/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-fv8v9gvh has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-c822ejx7'\n",
            "Created temporary directory: /tmp/pip-unpack-hhywf5tu\n",
            "Building wheels for collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-wheel-0rui3n5m\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-0rui3n5m\n",
            "  Running command /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-fv8v9gvh/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-fv8v9gvh/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-0rui3n5m\n",
            "\n",
            "\n",
            "  torch.__version__  = 1.9.0+cu102\n",
            "\n",
            "\n",
            "  /tmp/pip-req-build-fv8v9gvh/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/apex\n",
            "  copying apex/__init__.py -> build/lib/apex\n",
            "  creating build/lib/apex/parallel\n",
            "  copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  creating build/lib/apex/amp\n",
            "  copying apex/amp/opt.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
            "  copying apex/amp/compat.py -> build/lib/apex/amp\n",
            "  copying apex/amp/scaler.py -> build/lib/apex/amp\n",
            "  copying apex/amp/utils.py -> build/lib/apex/amp\n",
            "  copying apex/amp/amp.py -> build/lib/apex/amp\n",
            "  copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
            "  copying apex/amp/wrap.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__init__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__version__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/handle.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
            "  copying apex/amp/frontend.py -> build/lib/apex/amp\n",
            "  creating build/lib/apex/RNN\n",
            "  copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/models.py -> build/lib/apex/RNN\n",
            "  creating build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
            "  creating build/lib/apex/pyprof\n",
            "  copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n",
            "  creating build/lib/apex/normalization\n",
            "  copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
            "  copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
            "  creating build/lib/apex/contrib\n",
            "  copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
            "  creating build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n",
            "  creating build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
            "  creating build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
            "  creating build/lib/apex/mlp\n",
            "  copying apex/mlp/mlp.py -> build/lib/apex/mlp\n",
            "  copying apex/mlp/__init__.py -> build/lib/apex/mlp\n",
            "  creating build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
            "  creating build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n",
            "  creating build/lib/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n",
            "  creating build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n",
            "  creating build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
            "  creating build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "  creating build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/bottleneck.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/__init__.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/test.py -> build/lib/apex/contrib/bottleneck\n",
            "  creating build/lib/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/layer_norm.py -> build/lib/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/__init__.py -> build/lib/apex/contrib/layer_norm\n",
            "  creating build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n",
            "  creating build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
            "  creating build/lib/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/transducer.py -> build/lib/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/__init__.py -> build/lib/apex/contrib/transducer\n",
            "  creating build/lib/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/fmha.py -> build/lib/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/__init__.py -> build/lib/apex/contrib/fmha\n",
            "  creating build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/__init__.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/asp.py -> build/lib/apex/contrib/sparsity\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  creating apex.egg-info\n",
            "  writing apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "  writing top-level names to apex.egg-info/top_level.txt\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.7.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-0rui3n5m/apex-0.1-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'apex/__init__.py'\n",
            "  adding 'apex/RNN/RNNBackend.py'\n",
            "  adding 'apex/RNN/__init__.py'\n",
            "  adding 'apex/RNN/cells.py'\n",
            "  adding 'apex/RNN/models.py'\n",
            "  adding 'apex/amp/__init__.py'\n",
            "  adding 'apex/amp/__version__.py'\n",
            "  adding 'apex/amp/_amp_state.py'\n",
            "  adding 'apex/amp/_initialize.py'\n",
            "  adding 'apex/amp/_process_optimizer.py'\n",
            "  adding 'apex/amp/amp.py'\n",
            "  adding 'apex/amp/compat.py'\n",
            "  adding 'apex/amp/frontend.py'\n",
            "  adding 'apex/amp/handle.py'\n",
            "  adding 'apex/amp/opt.py'\n",
            "  adding 'apex/amp/rnn_compat.py'\n",
            "  adding 'apex/amp/scaler.py'\n",
            "  adding 'apex/amp/utils.py'\n",
            "  adding 'apex/amp/wrap.py'\n",
            "  adding 'apex/amp/lists/__init__.py'\n",
            "  adding 'apex/amp/lists/functional_overrides.py'\n",
            "  adding 'apex/amp/lists/tensor_overrides.py'\n",
            "  adding 'apex/amp/lists/torch_overrides.py'\n",
            "  adding 'apex/contrib/__init__.py'\n",
            "  adding 'apex/contrib/bottleneck/__init__.py'\n",
            "  adding 'apex/contrib/bottleneck/bottleneck.py'\n",
            "  adding 'apex/contrib/bottleneck/test.py'\n",
            "  adding 'apex/contrib/fmha/__init__.py'\n",
            "  adding 'apex/contrib/fmha/fmha.py'\n",
            "  adding 'apex/contrib/groupbn/__init__.py'\n",
            "  adding 'apex/contrib/groupbn/batch_norm.py'\n",
            "  adding 'apex/contrib/layer_norm/__init__.py'\n",
            "  adding 'apex/contrib/layer_norm/layer_norm.py'\n",
            "  adding 'apex/contrib/multihead_attn/__init__.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/optimizers/__init__.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam_v2.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam_v3.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
            "  adding 'apex/contrib/optimizers/fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fused_sgd.py'\n",
            "  adding 'apex/contrib/sparsity/__init__.py'\n",
            "  adding 'apex/contrib/sparsity/asp.py'\n",
            "  adding 'apex/contrib/sparsity/sparse_masklib.py'\n",
            "  adding 'apex/contrib/transducer/__init__.py'\n",
            "  adding 'apex/contrib/transducer/transducer.py'\n",
            "  adding 'apex/contrib/xentropy/__init__.py'\n",
            "  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
            "  adding 'apex/fp16_utils/__init__.py'\n",
            "  adding 'apex/fp16_utils/fp16_optimizer.py'\n",
            "  adding 'apex/fp16_utils/fp16util.py'\n",
            "  adding 'apex/fp16_utils/loss_scaler.py'\n",
            "  adding 'apex/mlp/__init__.py'\n",
            "  adding 'apex/mlp/mlp.py'\n",
            "  adding 'apex/multi_tensor_apply/__init__.py'\n",
            "  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
            "  adding 'apex/normalization/__init__.py'\n",
            "  adding 'apex/normalization/fused_layer_norm.py'\n",
            "  adding 'apex/optimizers/__init__.py'\n",
            "  adding 'apex/optimizers/fused_adagrad.py'\n",
            "  adding 'apex/optimizers/fused_adam.py'\n",
            "  adding 'apex/optimizers/fused_lamb.py'\n",
            "  adding 'apex/optimizers/fused_novograd.py'\n",
            "  adding 'apex/optimizers/fused_sgd.py'\n",
            "  adding 'apex/parallel/LARC.py'\n",
            "  adding 'apex/parallel/__init__.py'\n",
            "  adding 'apex/parallel/distributed.py'\n",
            "  adding 'apex/parallel/multiproc.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
            "  adding 'apex/parallel/sync_batchnorm.py'\n",
            "  adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
            "  adding 'apex/pyprof/__init__.py'\n",
            "  adding 'apex/pyprof/nvtx/__init__.py'\n",
            "  adding 'apex/pyprof/nvtx/nvmarker.py'\n",
            "  adding 'apex/pyprof/parse/__init__.py'\n",
            "  adding 'apex/pyprof/parse/__main__.py'\n",
            "  adding 'apex/pyprof/parse/db.py'\n",
            "  adding 'apex/pyprof/parse/kernel.py'\n",
            "  adding 'apex/pyprof/parse/nvvp.py'\n",
            "  adding 'apex/pyprof/parse/parse.py'\n",
            "  adding 'apex/pyprof/prof/__init__.py'\n",
            "  adding 'apex/pyprof/prof/__main__.py'\n",
            "  adding 'apex/pyprof/prof/activation.py'\n",
            "  adding 'apex/pyprof/prof/base.py'\n",
            "  adding 'apex/pyprof/prof/blas.py'\n",
            "  adding 'apex/pyprof/prof/conv.py'\n",
            "  adding 'apex/pyprof/prof/convert.py'\n",
            "  adding 'apex/pyprof/prof/data.py'\n",
            "  adding 'apex/pyprof/prof/dropout.py'\n",
            "  adding 'apex/pyprof/prof/embedding.py'\n",
            "  adding 'apex/pyprof/prof/index_slice_join_mutate.py'\n",
            "  adding 'apex/pyprof/prof/linear.py'\n",
            "  adding 'apex/pyprof/prof/loss.py'\n",
            "  adding 'apex/pyprof/prof/misc.py'\n",
            "  adding 'apex/pyprof/prof/normalization.py'\n",
            "  adding 'apex/pyprof/prof/optim.py'\n",
            "  adding 'apex/pyprof/prof/output.py'\n",
            "  adding 'apex/pyprof/prof/pointwise.py'\n",
            "  adding 'apex/pyprof/prof/pooling.py'\n",
            "  adding 'apex/pyprof/prof/prof.py'\n",
            "  adding 'apex/pyprof/prof/randomSample.py'\n",
            "  adding 'apex/pyprof/prof/recurrentCell.py'\n",
            "  adding 'apex/pyprof/prof/reduction.py'\n",
            "  adding 'apex/pyprof/prof/softmax.py'\n",
            "  adding 'apex/pyprof/prof/usage.py'\n",
            "  adding 'apex/pyprof/prof/utility.py'\n",
            "  adding 'apex/reparameterization/__init__.py'\n",
            "  adding 'apex/reparameterization/reparameterization.py'\n",
            "  adding 'apex/reparameterization/weight_norm.py'\n",
            "  adding 'apex-0.1.dist-info/LICENSE'\n",
            "  adding 'apex-0.1.dist-info/METADATA'\n",
            "  adding 'apex-0.1.dist-info/WHEEL'\n",
            "  adding 'apex-0.1.dist-info/top_level.txt'\n",
            "  adding 'apex-0.1.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-py3-none-any.whl size=205204 sha256=c1d63fece84f604c3bfe4793fc1f3e1c18713654fbd1c429290ac4a21af9288c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2i6tjmoi/wheels/02/1d/54/16beaa489b73437cc70f3f4ef0bbaa36f0ac443dd94834df91\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "  Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/apex\n",
            "  sysconfig: /usr/include/python3.7m/apex\n",
            "  Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\n",
            "  Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\n",
            "  Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\n",
            "\n",
            "Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/include/python3.7/UNKNOWN\n",
            "sysconfig: /usr/include/python3.7m/UNKNOWN\n",
            "Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/bin\n",
            "sysconfig: /usr/bin\n",
            "Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local\n",
            "sysconfig: /usr\n",
            "Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\n",
            "Successfully installed apex-0.1\n",
            "Removed build tracker: '/tmp/pip-req-tracker-c822ejx7'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51hvsYwVcDnr",
        "outputId": "55ce1a72-fb04-48d9-8267-6e50781929c6"
      },
      "source": [
        "!pip install timm"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[?25l\r\u001b[K     |                               | 10 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |                              | 20 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |                             | 30 kB 36.4 MB/s eta 0:00:01\r\u001b[K     |                            | 40 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |                           | 51 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |                          | 61 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |                          | 71 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |                         | 81 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |                        | 92 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |                       | 102 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |                      | 112 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |                     | 122 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |                    | 133 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |                   | 143 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |                   | 153 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |                  | 163 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |                 | 174 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |                | 184 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |               | 194 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |              | 204 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |             | 215 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |            | 225 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |            | 235 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |           | 245 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |          | 256 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |         | 266 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |        | 276 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |       | 286 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |      | 296 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |      | 307 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |     | 317 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |    | 327 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |   | 337 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |  | 348 kB 16.0 MB/s eta 0:00:01\r\u001b[K     | | 358 kB 16.0 MB/s eta 0:00:01\r\u001b[K     || 368 kB 16.0 MB/s eta 0:00:01\r\u001b[K     || 376 kB 16.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.0+cu102)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.4.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PWOmvG92YYe"
      },
      "source": [
        "# imports pytorch\n",
        "#import torch\n",
        "\n",
        "# imports the torch_xla package\n",
        "#import torch_xla\n",
        "#import torch_xla.core.xla_model as xm\n",
        "#import torch_xla.utils.serialization as xser"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFOSQ2ZOYsBE"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import timm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "\n",
        "import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from apex import amp, optimizers\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alwbj-nQVYEh",
        "outputId": "8ff94e30-1c48-4285-d7f7-345693a9c48e"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #(1)\n",
        "print(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpOkKGHG295j"
      },
      "source": [
        "#device = xm.xla_device()\n",
        "#print(device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEpiJqAKY96r"
      },
      "source": [
        "# setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcVSV2UCY1QG"
      },
      "source": [
        "class CONFIG :\n",
        "  TRAIN = '/content/label/train_finetune.txt'\n",
        "  VALID = '/content/label/val_finetune.txt'\n",
        "  num_of_worker = 4\n",
        "  base_model = 'resnetrs270'\n",
        "  batch_size = 32\n",
        "  num_epochs = 20\n",
        "  lr = 0.0005"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNRn0X-FIlFn"
      },
      "source": [
        "#net = timm.create_model(CONFIG.base_model, pretrained=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbR1OEMeYFE7"
      },
      "source": [
        "#net"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-WI3qjmcYYA"
      },
      "source": [
        "df_train = pd.read_table(CONFIG.TRAIN, sep=' ', header=None, names=['file','class'])\n",
        "df_valid = pd.read_table(CONFIG.VALID, sep=' ', header=None, names=['file','class'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "Qd0UHX7LcknC",
        "outputId": "5025ddd3-1a1a-46c0-ee32-cb88008fcfb9"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0/16330004.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0/16330005.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0/16330007.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0/16330009.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0/16330010.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             file  class\n",
              "0  0/16330004.jpg      0\n",
              "1  0/16330005.jpg      0\n",
              "2  0/16330007.jpg      0\n",
              "3  0/16330009.jpg      0\n",
              "4  0/16330010.jpg      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "u78OqXp8cmrj",
        "outputId": "d8a0df68-b1b1-4508-e2f9-8bb6b9f90872"
      },
      "source": [
        "df_valid.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0/16330020.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0/16330024.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0/16330029.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0/16330037.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0/16330046.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             file  class\n",
              "0  0/16330020.jpg      0\n",
              "1  0/16330024.jpg      0\n",
              "2  0/16330029.jpg      0\n",
              "3  0/16330037.jpg      0\n",
              "4  0/16330046.jpg      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEE0qadRdxdz"
      },
      "source": [
        "# data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h87DKqVrdruU"
      },
      "source": [
        "class LFFdataset(Dataset):\n",
        "    def __init__(self, path, df, transform = None):\n",
        "        self.transform = transform\n",
        "        self.df = df\n",
        "        self.path = path\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file = self.path + self.df['file'][idx] \n",
        "        #\n",
        "        img = Image.open(file)\n",
        "\n",
        "        #transform\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        label=self.df['class'][idx]\n",
        "\n",
        "        return img,label\n",
        " "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2Ni2a_ZtTgz"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybW3PKSvkWVc",
        "outputId": "54b2a88e-5821-4e57-f3fb-8fbae18b74eb"
      },
      "source": [
        "size = 256\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "                                      transforms.ToTensor(),\n",
        "#                                      transforms.RandomResizedCrop(size, scale=(0.3, 1.0), ratio=(3 / 4, 4 / 3), interpolation=2),\n",
        "                                      transforms.RandomResizedCrop(size, scale=(0.25, 1.0), ratio=(1, 1), interpolation=2),\n",
        "#                                      transforms.Resize((400,400)), \n",
        "#                                      transforms.RandomHorizontalFlip(),\n",
        "#                                      transforms.RandomVerticalFlip(),\n",
        "#                                      transforms.RandomErasing(),\n",
        "                                      transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
        "#                                      transforms.Resize((400,400)), \n",
        "                                      transforms.Normalize(\n",
        "                                          mean=[0.485, 0.456, 0.406],\n",
        "                                          std=[0.229, 0.224, 0.225]\n",
        "                                      )\n",
        "                                      ])\n",
        "\n",
        "transform_valid = transforms.Compose([\n",
        "                                      transforms.Resize((size, size)), \n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(\n",
        "                                          mean=[0.485, 0.456, 0.406],\n",
        "                                          std=[0.229, 0.224, 0.225]\n",
        "                                      ),\n",
        "                                          ])\n",
        "\n",
        "dataset_train = LFFdataset('./Train/', df_train, transform_train)\n",
        "dataset_valid = LFFdataset('./Val/', df_valid, transform_valid)\n",
        "dataloader = dict()\n",
        "dataloader['train'] = DataLoader(dataset_train, batch_size=CONFIG.batch_size, shuffle=True, num_workers=CONFIG.num_of_worker)\n",
        "dataloader['valid'] = DataLoader(dataset_valid, batch_size=CONFIG.batch_size, shuffle=False, num_workers=CONFIG.num_of_worker)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:835: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqm78dJbqzG2",
        "outputId": "ec752c0b-ddfb-45cf-b5dc-75c264f68270"
      },
      "source": [
        "#\n",
        "for img,label in dataloader['train']:\n",
        "    print('label=',label)\n",
        "    print('img.shape=',img.size())\n",
        "    break"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label= tensor([211, 483,  99, 424, 246, 933, 456, 101, 761, 782, 682, 424, 225, 880,\n",
            "        233, 635, 815, 345, 623, 965, 122, 759, 455, 320, 275, 303, 499, 439,\n",
            "        503,  64, 151, 633])\n",
            "img.shape= torch.Size([32, 3, 256, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz--UJ66t8jf"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77iSLUO0rGRM"
      },
      "source": [
        "class LFFmodel(nn.Module):\n",
        "    global CONFIG\n",
        "    def __init__(self):\n",
        "        super(LFFmodel, self).__init__()\n",
        "        \n",
        "        self.net = timm.create_model(CONFIG.base_model, pretrained=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        return x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoOO3ogTkXed"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIuKwd0EkWg_"
      },
      "source": [
        "if 0 :\n",
        "  # APEX  AMP \n",
        "  from apex import amp, optimizers\n",
        "\n",
        "  # AMP \n",
        "  model, optimizer = amp.initialize(model, optimizer, opt_level=args.opt_level, keep_batchnorm_fp32=args.keep_batchnorm_fp32, loss_scale=args.loss_scale)\n",
        "\n",
        "  # \n",
        "  with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "      scaled_loss.backward() "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZue8RTmml6L"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwEFHoQCDUC8",
        "outputId": "dcb5a3ee-873c-427c-be7e-e74a51280681"
      },
      "source": [
        "model = LFFmodel()\n",
        "model = model.to(device)\n",
        "\n",
        "PATH = '/content/drive/MyDrive/datas/last_resnetrs270.pth'\n",
        "BESTPATH = '/content/drive/MyDrive/datas/best_resnetrs270.pth'\n",
        "#model.load_state_dict(torch.load(PATH), map_location=torch.device(\"cpu\")))\n",
        "#model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "#criterionoptimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=CONFIG.lr)\n",
        "#optimizer = optim.Adam(model.net.classifier.parameters(), lr=0.0001)\n",
        "\n",
        "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n",
        "\n",
        "if 1:\n",
        "  print(\"read trained data................\")\n",
        "  checkpoint = torch.load(PATH)\n",
        "  #model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n",
        "  model.load_state_dict(checkpoint['model'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  amp.load_state_dict(checkpoint['amp'])\n",
        "  print(\"done.\", flush=True)\n",
        "\n",
        "for e in model.parameters() :\n",
        "  e.requires_grad = True\n",
        "for e in model.net.fc.parameters() :\n",
        "  e.requires_grad = True\n",
        "#for e in model.net.classifier.parameters() :\n",
        "#  e.requires_grad = True\n",
        "\n",
        "best = 0.0\n",
        "\n",
        "for epoch in range(CONFIG.num_epochs):\n",
        "    print('-------------', flush=True)\n",
        "    print('Epoch {}/{}'.format(epoch+1, CONFIG.num_epochs), flush=True)\n",
        "    \n",
        "    for phase in ['train', 'valid']:\n",
        "        \n",
        "        if phase == 'train':\n",
        "            # \n",
        "            model.train()\n",
        "            N = len(df_train)//CONFIG.batch_size\n",
        "        else:\n",
        "            # \n",
        "            model.eval()\n",
        "            N = len(df_valid)//CONFIG.batch_size\n",
        "        \n",
        "        # \n",
        "        epoch_loss = 0.0\n",
        "        # \n",
        "        epoch_corrects = 0\n",
        "        \n",
        "\n",
        "        # DataLoader\n",
        "        for inputs, labels in tqdm.tqdm(dataloader[phase], total = N) :\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # optimizer\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # \n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                # \n",
        "                loss = criterion(outputs, labels)\n",
        "                \n",
        "                # \n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                \n",
        "                # \n",
        "                if phase == 'train':\n",
        "                    # \n",
        "                    #loss.backward()\n",
        "                    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                      scaled_loss.backward() \n",
        "                    # \n",
        "                    optimizer.step()\n",
        "                    #xm.optimizer_step(optimizer, barrier=True)\n",
        "\n",
        "                \n",
        "                # \n",
        "                # loss\n",
        "                # PyTorchloss\n",
        "                # \n",
        "                # /\n",
        "                # \n",
        "                epoch_loss += loss.detach().cpu().item() * inputs.size(0)\n",
        "\n",
        "                # \n",
        "                epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # epochloss\n",
        "        epoch_loss = epoch_loss / len(dataloader[phase].dataset)\n",
        "        epoch_acc = epoch_corrects.double() / len(dataloader[phase].dataset)\n",
        "\n",
        "        if phase == 'train':\n",
        "          # Save checkpoint\n",
        "          checkpoint = {\n",
        "              'model': model.state_dict(),\n",
        "              'optimizer': optimizer.state_dict(),\n",
        "              'amp': amp.state_dict()\n",
        "          }\n",
        "          torch.save(checkpoint, PATH)\n",
        "          #PATH = '/content/drive/MyDrive/datas/last_resnetrs152.pth'\n",
        "          #torch.save(model.state_dict(), PATH)\n",
        "          #xm.save(model.state_dict(), PATH)\n",
        "        else :          \n",
        "          if best < epoch_acc :\n",
        "            best = epoch_acc \n",
        "            # Save checkpoint\n",
        "            checkpoint = {\n",
        "                'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'amp': amp.state_dict()\n",
        "            }\n",
        "            torch.save(checkpoint, BESTPATH)\n",
        "\n",
        "        print(\"\")\n",
        "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rs-weights/resnetrs270_ema-b40e674c.pth\" to /root/.cache/torch/hub/checkpoints/resnetrs270_ema-b40e674c.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
            "read trained data................\n",
            "done.\n",
            "-------------\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|       | 2241/9914 [23:26<1:11:27,  1.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|      | 3602/9914 [37:32<57:25,  1.83it/s]  "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 76%|  | 7498/9914 [1:18:01<21:39,  1.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9915it [1:43:16,  1.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train Loss: 0.3213 Acc: 0.8994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1671it [04:15,  6.53it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "valid Loss: nan Acc: 0.7851\n",
            "-------------\n",
            "Epoch 2/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 19%|        | 1863/9914 [19:32<1:15:38,  1.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|     | 4979/9914 [52:00<46:29,  1.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|  | 7420/9914 [1:17:31<24:28,  1.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9915it [1:43:39,  1.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train Loss: 0.3019 Acc: 0.9055\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1671it [04:17,  6.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "valid Loss: nan Acc: 0.7782\n",
            "-------------\n",
            "Epoch 3/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|        | 1954/9914 [20:21<1:18:39,  1.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|       | 2188/9914 [22:46<1:12:09,  1.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 63%|   | 6203/9914 [1:04:04<32:42,  1.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 71%|   | 6998/9914 [1:12:04<26:42,  1.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|  | 7918/9914 [1:21:24<20:34,  1.62it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMu_-8EyYTol"
      },
      "source": [
        "timm.list_models()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAG_w4I7-mtz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}